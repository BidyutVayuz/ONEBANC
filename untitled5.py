# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/130mxj5KIpaJsW4YxyaxiBmPTj6mb5SkS
"""



"""**Akash Sharma**  
**NIT Raipur**

**OneBanc_Data Science Assignment**

#Importing Libraries
"""

import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt

"""#import data"""

file = pd.read_csv('DataScienceCleanStatement.csv')
file.head()

file.info()

"""#Remove the Spaces in before and after the Column name

"""

cols = dict([(x,x.strip()) for x in list(file.columns)])
file.rename(columns = cols, inplace=True)

file.head()



"""#clean the country column"""

l = file['Country'].value_counts().index
l

filter1 = file['Country'] == 'Haryana'
filter2 = file['Country'] == 'Delhi'
filter3 = file['Country'] == 'Rajasthan'
file['Country'].where((~(filter1 | filter2 | filter3)), 'India', inplace = True)



"""#Remove unnacessary column"""

file.drop(['Unnamed: 12'], axis = 1, inplace=True)

file.isna().sum()

"""#Defining the function to remove front and trailing spaces from column values"""

def space_remover(col):
    lst =[]
    for x in file[col]:
        lst.append(x.strip().upper())
    file[col] = lst
cols = file.columns
space_remover('InternationTransactionAmount')   # removing front and rear space from

"""#Cleaning InternationTransactionAmount column"""

file.iloc[182,2:8] = ['0','Food','-438.9','VIBHORE GOYAL','Domestic',np.nan]
file.iloc[477, 4:11] = ['-2899','JASJIT KAUR','DOMESTIC','INR','BLOCK S','GURUGRAM','HARYANA']
file.iloc[755, 4:11] = ['-2348','VIBHORE GOYAL','DOMESTIC','INR','D1 BLOCK','GURUGRAM',"HARYANA"]
file.iloc[789, 4:11] = ['-2391','VIBHORE GOYAL','DOMESTIC','INR','CIVIL LINES','JAIPUR','RAJASTHAN']

"""#Filling null Values"""

from sklearn.impute import SimpleImputer
missing_columns = file.iloc[:,:]
imputer = SimpleImputer(strategy='most_frequent')
cols_imputed = imputer.fit_transform(missing_columns)
file.iloc[:,:] = cols_imputed

file.isna().sum()

"""# Remove spaces before and after."""

cols = file.columns
for column in cols:
    x = file[column]
    x = [y.strip().upper() for y in list(x)]
    file[column] = x

x = file['Description']
x = [' '.join(x[i].split()) for i in range (len(x))]
file['Description'] = x

"""#Cleaning and Proper orienting the data


"""

# making city names separated in column
def city_separator(city_):

    x = list(file['Description'])
    city = city_.lower()

    for i in range(len(x)):
        v = x[i].casefold()

        if city in v:
            st = v.partition(city)
            var = []
            for k in st:
                
                if k != '':
                    var.append(k.strip())

            x[i]=' '.join(var).upper()
         
    file['Description'] = x

city_list = list(file['City'].value_counts().index)
city_list.pop(2)
city_list.extend(['GURGAON','LONDON','DELHI', 'JAIPUR'])     # gurgaon not in city
for i in city_list:
   city_separator(i)

file['Description']



"""#Converting numerical columns to float type from object type"""

file.columns

file['InternationTransactionAmount'] = file['InternationTransactionAmount'].astype(np.float64)
file['Amount'] = file['Amount'].astype(np.float64)

file.info()



"""#Saving the clean file"""

file.to_csv('Modified.csv')

"""#Selecting The Columns of Object type only"""

text_col = list(file.select_dtypes(include= 'object').columns)[1:]
text_col

file.head()

newfile = file.copy()

newfile.head()

newfile.drop(['Date','Category'], axis = 1, inplace=True)

newfile.head()

city_unique = new_file['City'].value_counts().index
city_unique.sort_values()

newfile['State'].where(new_file['City'] != 'SINGAPORE', 'SINGAPORE', inplace=True)
newfile['State'].where(new_file['City'] != 'NEW DELHI', 'NEW DELHI`', inplace=True)

newfile

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

"""#Applying the label encoder to categorical columns"""

newfile[newfile.select_dtypes(include=['object']).columns] = newfile[newfile.select_dtypes(include=['object']).columns].apply(le.fit_transform)
newfile.head()

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

"""#Applying Minmax scaling to dataframe"""

newfile = pd.DataFrame(scaler.fit_transform(newfile), columns = newfile.columns)
newfile.head()

from sklearn.cluster import KMeans

k_means = KMeans(n_clusters=3, random_state= 42)

k_means.fit(newfile)

import numpy as np
label = k_means.labels_
np.unique(label)

n_classes = range(1,20)

k_means = [KMeans(n_clusters= i, random_state = 42) for i in n_classes]
score = [k_means[i].fit(newfile).score(newfile) for i in range(len(k_means))]

import matplotlib.pyplot as plt
plt.figure(figsize = (12,6))
plt.plot(score)
plt.grid()
plt.show()

score = np.absolute(score)

plt.figure(figsize = (12,12))
plt.plot(n_classes, score, 'r', marker = "*")
plt.xlabel('number of clusters')
plt.ylabel('Sum Square Distance')
plt.title('Elbow Curve')
plt.yticks([x for x in range(60,600,20)])
plt.xticks([x for x in range(0,20)])
plt.grid()
plt.show()

kmeans = KMeans(n_clusters = 14, random_state = 42)
kmeans.fit(newfile)

category = list(kmeans.labels_)

file['Category'] = category

file.head(30)

clusters = kmeans.predict(newfile)

newfile.to_csv('dataonebanc.csv')